{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Classification is the process of predicting the class of given data points\n",
    "    * Estimate the target the class based on one or more independent variables\n",
    "* In Regression the aim is to find a continuous function that best represent the data examples\n",
    "* In Classification the aim is to label the predictions according to the features\n",
    "* Binary classification: only two classes are involved\n",
    "* Multiclass classification: involves assigning an object to one of several classes\n",
    "\n",
    "<img style=\"float: left;\" width=\"500\" src=\"images/classification_regression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data\n",
    "\n",
    "* Categorical varibles can be either **Nominal** or **Ordinal **\n",
    "* Nominal data: Cannot be numerically organized or ranked\n",
    "    * Nominal classes are simply labels\n",
    "    * Example: `pass` or `fail` for a student's test result\n",
    "* Ordinal data: the order of the classes important and significant\n",
    "    * Example:  feedback on some service, ranging from `1 (poor)` to `5 (very good)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "* Many classification methods have been developed binary and multiclass classification\n",
    "* Some examples are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "* In statistics, the logistic model uses a logistic function to model a **binary dependent variable**\n",
    "    * This method can be extended to Multinomial and Ordinal cases\n",
    "* The dependent variable in logistic regression follows Bernoulli Distribution\n",
    "* Estimation is done through **maximum likelihood**\n",
    "* Hypotesis is the sigmoid function:\n",
    "$h_\\theta = \\sigma(z)$\n",
    "\n",
    "<img style=\"float: left;\" width=\"500\" src=\"images/linear_vs_logistic_regression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)\n",
    "\n",
    "* The prediction consists of the $k$ closest training examples in the feature space\n",
    "    * Prediction is assigned to the class most common among its $k$ nearest neighbors \n",
    "    * $k$ is a positive integer, typically small\n",
    "\n",
    "<img style=\"float: left;\" width=\"500\" src=\"images/knn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "> A family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naive) independence assumptions between the features\n",
    "\n",
    "* Tthe value of a particular feature is assumed independent of the value of any other feature, given the class variable\n",
    "    * Thats the reason for the name \"naive\"\n",
    "* Example: a fruit may be considered to be an apple if it is red, round, and about 10 cm in diameter. \n",
    "    * A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple, regardless of any possible correlations between the color, roundness, and diameter features.\n",
    "\n",
    "<img style=\"float: left;\" width=\"500\" src=\"images/naive_bayes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification\n",
    "\n",
    "* Uses a tree-like model of decisions and their possible consequences\n",
    "\n",
    "* It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed\n",
    "\n",
    "* The learning algorithm has to design a tree structure that maximizes the prediction accuracy\n",
    "\n",
    "<img style=\"float: left;\" width=\"500\" src=\"images/dt_example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Artificial Neural Networks (ANNs)\n",
    "\n",
    "* ANNs aim to model the brain functionality \n",
    "* This model is the basis to develop algorithms that can be used to find complex patterns\n",
    "* ANNs are able to model non-linear and really complex feature relations\n",
    "* ANNs do not impose restrictions on the input variables \n",
    "    * e.g. distribution restrictions\n",
    "\n",
    "#### Application examples of ANNs\n",
    "\n",
    "* Image processing and classification\n",
    "* Control and Optimization\n",
    "* Forecasting weather patterns\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" width=\"500\" src=\"images/nn_classification.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
